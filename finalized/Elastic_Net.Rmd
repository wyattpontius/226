---
title: "Elastic_Net"
output: word_document
---

```{r setup}
#import train and validate and get ride of X1 column
library(ggplot2)
library(plyr)
setwd("~/Documents/226Project")
train_data = read.csv(file = "final_train_data.csv")
validation_data = read.csv(file = "final_validation_data.csv")
train = train_data[,-1]
validate = validation_data[,-1]
```

```{r}
#function to standardize numeric cols
stdize = function(df) {
  continuous_covariates = c("Model_Year", "Mileage", "Feedback_Perc", "N_Reviews", "review_polarity", "review_positivity")
  for(i in 1:length(continuous_covariates)) {
    x_bar = mean(df[,continuous_covariates[[i]]])
    scale = sd(df[,continuous_covariates[[i]]])
    df[,continuous_covariates[[i]]] = (df[,continuous_covariates[[i]]]-x_bar)/scale
  }
  return(df)
}
#test out function
df = stdize(train)
df
```

```{r}
#construct stepwise model
fm.lower = lm(data = train, Price ~ 1)
fm.upper = lm(data = train, Price ~ . + I(Model_Year^2) + I(Mileage^2))
stepped = step(fm.lower,
     scope = list(lower = fm.lower,
                  upper = fm.upper),
     direction = "forward")
stepwise_formula = formula(stepped)
```

```{r}
#stepwise results
library(modelr)
stepwise_formula
stepwise_model = lm(stepwise_formula, train)
summary(stepwise_model)
print("forward-stepwise train error")
rmse(stepwise_model, train)
print("forward-stepwise validation error")
rmse(stepwise_model, validate)
```

```{r}
#dumb LM
dumb_linear_model = lm( Price ~ 1, data = train)
print("simple LM train error")
rmse(dumb_linear_model, train)
print("simple LM validation error")
rmse(dumb_linear_model, validate)
```


```{r}
#simple LM (only covariates from data exploration)
linear_model = lm(data = train, Price ~ . + I(Model_Year^2) + I(Mileage^2))
print("simple LM train error")
rmse(linear_model, train)
print("simple LM validation error")
rmse(linear_model, validate)
```

```{r}
#kitchen sink LM
kitchen_sink_linear_model = lm(data = train, Price ~ . + I(Model_Year^2) + I(Mileage^2))
print("kitchen sink LM train error")
rmse(kitchen_sink_linear_model, train)
print("kitchen sink LM validation error")
rmse(kitchen_sink_linear_model, validate)
```


```{r}
#lasso, ridge, and elasticnet for LM
library(glmnet)
total = rbind(train, validate)
total = stdize(total)
X = model.matrix(Price ~ 0 + . + I(Model_Year^2) + I(Mileage^2)  + Make:Model_Year, total)
Y = total$Price
X.train = X[1:nrow(train),]
X.test = X[(nrow(train)+1):nrow(total),]
Y.train = Y[1:nrow(train)]
Y.test = Y[(nrow(train)+1):nrow(total)]
length(Y.train)
length(X.train)
# set lambda sequence to use for lasso and ridge
lambdas = 10^seq(-2,5,0.1)
# ridge regression
fm.ridge = glmnet(X.train, Y.train, alpha = 0, lambda = lambdas, thresh = 1e-12)
# test error of ridge regression at each lambda
ridge.test = adply(lambdas, 1, function(l) {
  return( data.frame(l, mean( (Y.test - predict(fm.ridge, s = l, newx = X.test))^2 ), "Ridge" ))
}, .id = NULL)
colnames(ridge.test) = c("lambda", "TestErr", "Model")
#lasso
fm.lasso = glmnet(X.train, Y.train, alpha = 1, lambda = lambdas, thresh = 1e-12)
# test error of lasso at each lambda
lasso.test = adply(lambdas, 1, function(l) {
  return( data.frame(l, mean( (Y.test - predict(fm.lasso, s = l, newx = X.test))^2 ), "Lasso" ))
}, .id = NULL)
colnames(lasso.test) = c("lambda", "TestErr", "Model")
# elasticnet regression
fm.elasticnet = glmnet(X.train, Y.train, alpha = 0.5, lambda = lambdas, thresh = 1e-12)
# test error of elasticnet regression at each lambda
elasticnet.test = adply(lambdas, 1, function(l) {
  return( data.frame(l, mean( (Y.test - predict(fm.elasticnet, s = l, newx = X.test))^2 ), "ElasticNet" ))
}, .id = NULL)
colnames(elasticnet.test) = c("lambda", "TestErr", "Model")
# combine test error of each model into one data frame
test.df = rbind(ridge.test, lasso.test, elasticnet.test)
test.df$Model = factor(test.df$Model)
# plot test error
ggplot(data = test.df, aes(x = lambda, y = TestErr, color = Model)) + 
  geom_line()  + scale_x_log10() + ylab("Test set error")
# What is the minimum test error for the different techniques?
ridge.min.err = min(ridge.test$TestErr)
lasso.min.err = min(lasso.test$TestErr)
elasticnet.min.err = min(elasticnet.test$TestErr)
print("ridge min error:")
sqrt(ridge.min.err)
print("lasso min error:")
sqrt(lasso.min.err)
print("elasticnet min error:")
sqrt(elasticnet.min.err)
# Which lambda achieves the minimum test error for the regularization techniques?
ridge.min.l = lambdas[which.min(ridge.test$TestErr)]
lasso.min.l = lambdas[which.min(lasso.test$TestErr)]
elasticnet.min.l = lambdas[which.min(elasticnet.test$TestErr)]
print("ridge min lambda")
ridge.min.l
print("lasso min lambda")
lasso.min.l
print("elasticnet min lambda")
elasticnet.min.l
# What are the coefficients at the test error minimizing models?
#cbind(predict(fm.lasso, s = lasso.min.l, type = "coefficients"), 
#predict(fm.ridge, s = ridge.min.l, type = "coefficients"))
```
```{r}
x = c(1, 1, 0)
y = c(1, 0, 1)
table(x,y)
```

```{r}
library("e1071")
svm_model <- svm(New ~ ., data=train, type = "C-classification")
summary(svm_model)
pred = predict(svm_model, train)
table(pred, train$New)
```

```{r}
#SVM
library("e1071")
data = train[1:1000,]
#tune gamma
#tuned_parameters <- tune.svm(has_warranty ~ ., data = data, type = "C-classification", gamma = 10^(-5:-1), cost = 10^(-3:1))
#summary(tuned_parameters)
best.gamma = .1
best.cost = 10
svm_model = svm(has_warranty ~., data = train, type = "C-classification", kernel = "radial", gamma = best.gamma, cost = best.cost)
#train prediction
pred = predict(svm_model, train)
t1 = table(predict(svm_model), train$has_warranty, dnn=c("Prediction", "Actual"))
t1
average.loss.train = (t1[1,1] + t1[2,2])/sum(t1)
average.loss.train
#validation prediction
t2 = table(predict(svm_model, newdata = validate), validate$has_warranty, dnn=c("Prediction", "Actual"))  
t2
average.loss.validate = (t2[1,1] + t2[2,2])/sum(t2)
average.loss.validate
```
