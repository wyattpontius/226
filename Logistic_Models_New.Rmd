---
title: "Classification_Models"
output: word_document
---

```{r}
#import train and validate and get ride of X1 column
library(ggplot2)
library(dplyr)
library(plyr)
setwd("~/Documents/226Project")
train = read.csv(file = "final_train_data.csv")
validate = read.csv(file = "final_validation_data.csv")
train = train[,-1]
validate = validate[,-1]

train
```

```{r}
#function to standardize numeric cols

stdize = function(df) {
  continuous_covariates = c("Model_Year", "Mileage", "Feedback_Perc", "N_Reviews", "review_polarity", "review_positivity")
  for(i in 1:length(continuous_covariates)) {
    x_bar = mean(df[,continuous_covariates[[i]]])
    scale = sd(df[,continuous_covariates[[i]]])
    df[,continuous_covariates[[i]]] = (df[,continuous_covariates[[i]]]-x_bar)/scale
  }
  return(df)
}
#test out function
train = stdize(train)
train = stdize(validate)

```

#normal logistic regression
```{r}
library(ROCR)
model_logistic = glm(has_warranty ~ .  + I(Model_Year^2) + I(Mileage^2) + Make:Model_Year + Make:Type, train, family = 'binomial')

summary(model_logistic)

#generate model predictions for train data
logistic_train_data = train %>%
  mutate(
    prediction = predict(model_logistic, data = train, type = 'response'),
    pred_new = ifelse(prediction >= 0.5, TRUE, FALSE)
    )

#compute accuracy for train data
accuracy_train = logistic_train_data %>%
  summarize(accuracy_train = mean(has_warranty == pred_new))
accuracy_train

#calculates precision (proportion of 'positive' predictions that are 'true') for train data
precision_train = logistic_train_data %>%
  filter(pred_new == TRUE) %>%
  summarize(precision_train = mean(has_warranty == TRUE))
precision_train

#calculates recall (proportion of all 'true' instances that are 'positive') for train data
recall_train = logistic_train_data %>%
  filter(has_warranty == TRUE) %>%
  summarize(recall_train = mean(pred_new == TRUE))
recall_train

#calcualtes auc for train data
pred = prediction(logistic_train_data$prediction, logistic_train_data$New)
train_auc = performance(pred, "auc")
train_auc = unlist(slot(train_auc, "y.values"))
train_auc
```

#stepwise logistic model
```{r}
#construct stepwise model
total.logistic.model = glm(data = train, has_warranty ~ . + I(Model_Year^2) + I(Mileage^2) + Make:Model_Year + Make:Type, family = 'binomial')
step.logistic.model = step(total.logistic.model, direction = "backward")
step.logistic.model$anova

#best formula: has_warranty ~ Price + Model_Year + Make + Type + Feedback_Perc + N_Reviews + Seller_Status + Auction + Buy_Now + uses_excl + review_polarity + New + I(Model_Year^2)
```

```{r}
#generate model predictions for validation data
logistic_validation_data = validate %>%
  mutate(
    prediction = predict(model_logistic, newdata = validate, type = 'response'),
    pred_new = ifelse(prediction >= 0.5, TRUE, FALSE)
    )

#compute accuracy for validation data
accuracy_validation = logistic_validation_data %>%
  summarize(accuracy_validation = mean(has_warranty == pred_new))
accuracy_validation

#calculates precision (proportion of 'positive' predictions that are 'true') for validation data
precision_validation = logistic_validation_data %>%
  filter(pred_new == TRUE) %>%
  summarize(precision_validation = mean(has_warranty == TRUE))
precision_validation

#calculates recall (proportion of all 'true' instances that are 'positive') for validation data
recall_validation = logistic_validation_data %>%
  filter(has_warranty == TRUE) %>%
  summarize(recall_validation = mean(pred_new == TRUE))
recall_validation

#calcualtes auc for validation data
pred = prediction(logistic_validation_data$prediction, logistic_validation_data$New)
validation_auc = performance(pred, "auc")
validation_auc = unlist(slot(validation_auc, "y.values"))
validation_auc
```

```{r}
#lasso and ridge for logistic
library(glmnet)
total = rbind(train, validate)
total = stdize(total)

cols <- sapply(total, is.logical)
total[,cols] <- lapply(total[,cols], as.numeric)
total

X = model.matrix(has_warranty ~ 0 + ., total)
Y = total$has_warranty
X.train = X[1:nrow(train),]
X.test = X[(nrow(train)+1):nrow(total),]
Y.train = Y[1:nrow(train)]
Y.test = Y[(nrow(train)+1):nrow(total)]

# set lambda sequence to use for lasso and ridge
lambdas = 10^seq(-2,5,0.1)

# ridge regression
fm.ridge = cv.glmnet(X.train, Y.train, alpha = 0, family = "binomial", thresh = 1e-12)
fm.ridge$lambda.min

mean( abs(Y.test - as.numeric(predict(fm.ridge, newx = X.test, type="class", s = "lambda.min"))))

fm.lasso = cv.glmnet(X.train, Y.train, alpha = 1, family = "binomial", thresh = 1e-12)

fm.lasso$lambda.min
mean( abs(Y.test - as.numeric(predict(fm.lasso, newx = X.test, type="class", s = "lambda.min"))))

```



